{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gilad/miniforge3/envs/ys-dev/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# This notebook imports battles from LS.\n",
    "# Note: it requires installing the `gradio_client` package, which is not a requirement of the repo in general.\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime  # noqa\n",
    "import sys  # noqa\n",
    "from time import time  # noqa: E402\n",
    "\n",
    "import pandas as pd  # noqa\n",
    "from gradio_client import Client  # noqa\n",
    "from sqlmodel import Session, select  # noqa\n",
    "from tqdm.notebook import tqdm  # noqa\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from backend.db import get_engine  # noqa\n",
    "from backend.llm.ranking import ChoixRankerConfIntervals  # noqa\n",
    "from db.ratings import Category, OVERALL_CATEGORY_NAME, OVERALL_CATEGORY_DESCRIPTION  # noqa\n",
    "from db.language_models import LanguageModel, LicenseEnum  # noqa\n",
    "from db.ratings import Rating  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hf_license(ls_license: str) -> LicenseEnum:\n",
    "    if ls_license == \"Proprietary\":\n",
    "        return LicenseEnum.other\n",
    "    elif ls_license in [\"Apache-2.0\", \"Apache 2.0\"]:\n",
    "        return LicenseEnum.apache_2_0\n",
    "    elif ls_license == \"Llama 2 Community\":\n",
    "        return LicenseEnum.llama2\n",
    "    elif ls_license == \"MIT\":\n",
    "        return LicenseEnum.mit\n",
    "    elif ls_license == \"Qianwen LICENSE\":\n",
    "        return LicenseEnum.other\n",
    "    elif ls_license == \"Non-commercial\":\n",
    "        return LicenseEnum.other\n",
    "    elif ls_license == \"Gemma license\":\n",
    "        return LicenseEnum.gemma\n",
    "    elif ls_license == \"CC-BY-NC-4.0\":\n",
    "        return LicenseEnum.cc_by_nc_4_0\n",
    "    elif ls_license == \"CC-BY-NC-SA-4.0\":\n",
    "        return LicenseEnum.cc_by_nc_sa_4_0\n",
    "    elif ls_license in [\"Llama 3.1 Community\", \"Llama 3 Community\"]:\n",
    "        return LicenseEnum.llama3\n",
    "    elif ls_license in [\"DeepSeek License\", \"DeepSeek\"]:\n",
    "        return LicenseEnum.other\n",
    "    elif ls_license == \"Jamba Open\":\n",
    "        return LicenseEnum.other\n",
    "    elif ls_license == \"NVIDIA Open Model\":\n",
    "        return LicenseEnum.other\n",
    "    elif ls_license == \"Yi License\":\n",
    "        return LicenseEnum.other\n",
    "    elif ls_license == \"AI2 ImpACT Low-risk\":\n",
    "        return LicenseEnum.other\n",
    "    elif ls_license == \"DBRX LICENSE\":\n",
    "        return LicenseEnum.other\n",
    "    elif ls_license == \"Mistral Research\":\n",
    "        return LicenseEnum.other\n",
    "    elif ls_license == \"Falcon-180B TII License\":\n",
    "        return LicenseEnum.other\n",
    "    else:\n",
    "        return LicenseEnum.unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://lmsys-chatbot-arena-leaderboard.hf.space ‚úî\n",
      "Loaded 136 models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank* (UB)</th>\n",
       "      <th>ü§ñ Model</th>\n",
       "      <th>‚≠ê Arena Score</th>\n",
       "      <th>üìä 95% CI</th>\n",
       "      <th>üó≥Ô∏è Votes</th>\n",
       "      <th>Organization</th>\n",
       "      <th>License</th>\n",
       "      <th>Knowledge Cutoff</th>\n",
       "      <th>model_url</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_internal_name</th>\n",
       "      <th>hf_license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;a target=\"_blank\" href=\"https://x.com/OpenAID...</td>\n",
       "      <td>1316</td>\n",
       "      <td>+4/-4</td>\n",
       "      <td>24023</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>2023/10</td>\n",
       "      <td>https://x.com/OpenAIDevs/status/18235103956190...</td>\n",
       "      <td>ChatGPT-4o-latest (2024-08-08)</td>\n",
       "      <td>chatgpt-4o-latest (2024-08-08)</td>\n",
       "      <td>LicenseEnum.other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;a target=\"_blank\" href=\"https://aistudio.goog...</td>\n",
       "      <td>1301</td>\n",
       "      <td>+5/-5</td>\n",
       "      <td>19910</td>\n",
       "      <td>Google</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>2023/11</td>\n",
       "      <td>https://aistudio.google.com/app/prompts/new_ch...</td>\n",
       "      <td>Gemini-1.5-Pro-Exp-0827</td>\n",
       "      <td>gemini-1.5-pro-exp-0827</td>\n",
       "      <td>LicenseEnum.other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank* (UB)                                            ü§ñ Model ‚≠ê Arena Score  \\\n",
       "0          1  <a target=\"_blank\" href=\"https://x.com/OpenAID...          1316   \n",
       "1          2  <a target=\"_blank\" href=\"https://aistudio.goog...          1301   \n",
       "\n",
       "  üìä 95% CI  üó≥Ô∏è Votes Organization      License Knowledge Cutoff  \\\n",
       "0    +4/-4     24023       OpenAI  Proprietary          2023/10   \n",
       "1    +5/-5     19910       Google  Proprietary          2023/11   \n",
       "\n",
       "                                           model_url  \\\n",
       "0  https://x.com/OpenAIDevs/status/18235103956190...   \n",
       "1  https://aistudio.google.com/app/prompts/new_ch...   \n",
       "\n",
       "                       model_name             model_internal_name  \\\n",
       "0  ChatGPT-4o-latest (2024-08-08)  chatgpt-4o-latest (2024-08-08)   \n",
       "1         Gemini-1.5-Pro-Exp-0827         gemini-1.5-pro-exp-0827   \n",
       "\n",
       "          hf_license  \n",
       "0  LicenseEnum.other  \n",
       "1  LicenseEnum.other  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def internal_name(name: str) -> str:\n",
    "    return (\n",
    "        name.lower()\n",
    "        .replace(\"openassistant\", \"oasst\")\n",
    "        .replace(\"wizardlm-13b-v1.2\", \"wizardlm-13b\")\n",
    "        .replace(\"wizardlm-70b-v1.0\", \"wizardlm-70b\")\n",
    "        .replace(\"palm-chat-bison-001\", \"palm-2\")\n",
    "        .replace(\"mistral-7b-instruct-v0.1\", \"mistral-7b-instruct\")\n",
    "        .replace(\"mistral-7b-instruct-v0.2\", \"mistral-7b-instruct\")\n",
    "        .replace(\"nv-llama2-70b-steerlm-chat\", \"llama2-70b-steerlm-chat\")\n",
    "    )\n",
    "\n",
    "\n",
    "# Get the LS leaderboard.\n",
    "client = Client(\"lmsys/chatbot-arena-leaderboard\")\n",
    "result = client.predict(category=\"Overall\", api_name=\"/update_leaderboard_and_plots\")\n",
    "\n",
    "# Put in a dataframe, and infer the model name and url.\n",
    "df = pd.DataFrame(result[0][\"value\"][\"data\"], columns=result[0][\"value\"][\"headers\"])\n",
    "df[\"model_url\"] = df[\"ü§ñ Model\"].str.extract(r'href=\"([^\"]+)\"')[0]\n",
    "df[\"model_name\"] = df[\"ü§ñ Model\"].str.extract(r\">([^<]+)<\")[0]\n",
    "df[\"model_internal_name\"] = df[\"model_name\"].apply(internal_name)\n",
    "df[\"hf_license\"] = df[\"License\"].apply(get_hf_license)\n",
    "print(f\"Loaded {len(df)} models\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Committing 0 new objects\n"
     ]
    }
   ],
   "source": [
    "# Load the models into the database, if they don't exist.\n",
    "models_names_to_llms = {}\n",
    "\n",
    "with Session(get_engine()) as session:\n",
    "    for _, row in df.iterrows():\n",
    "        llm = session.exec(\n",
    "            select(LanguageModel).where(LanguageModel.internal_name == row[\"model_internal_name\"])\n",
    "        ).first()\n",
    "        if not llm:\n",
    "            print(f\"Adding {row['model_internal_name']}\")\n",
    "            llm = LanguageModel(\n",
    "                name=row[\"model_name\"],\n",
    "                internal_name=row[\"model_internal_name\"],\n",
    "                license=row[\"hf_license\"],\n",
    "                label=row[\"model_name\"],\n",
    "                family=row[\"Organization\"],\n",
    "                # TODO: Add actual avatar_url\n",
    "                avatar_url=row[\"model_url\"],\n",
    "            )\n",
    "            session.add(llm)\n",
    "        models_names_to_llms[row[\"model_internal_name\"]] = llm\n",
    "\n",
    "    category = session.exec(select(Category).where(Category.name == OVERALL_CATEGORY_NAME)).first()\n",
    "    if not category:\n",
    "        category = Category(name=OVERALL_CATEGORY_NAME, description=OVERALL_CATEGORY_DESCRIPTION)\n",
    "        session.add(category)\n",
    "\n",
    "    print(f\"Committing {len(session.new)} new objects\")\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1799991 raw battles\n"
     ]
    }
   ],
   "source": [
    "# This data is also found in https://drive.google.com/drive/u/0/folders/1660oK765zlYCNf8B-cF82T_CKnQvc9cK as backup.\n",
    "\n",
    "local_file_name = \"../tmp/clean_battle_20240814_public.json\"\n",
    "with open(local_file_name) as file:\n",
    "    battles = pd.read_json(file).sort_values(ascending=True, by=[\"tstamp\"])\n",
    "print(f\"Loaded {len(battles)} raw battles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering battles with unknown models and dupes: 781641 battles\n"
     ]
    }
   ],
   "source": [
    "models = set(df[\"model_internal_name\"].unique())\n",
    "battles = battles[\n",
    "    # only include anonymous battles where both models are in the leaderboard.\n",
    "    (battles.model_a.isin(models)) & (battles.model_b.isin(models)) & (battles[\"anony\"] == True)  # noqa\n",
    "]\n",
    "# de-duplicate in the same way as LS.\n",
    "battles = battles[battles[\"dedup_tag\"].apply(lambda x: x.get(\"sampled\", False))]\n",
    "\n",
    "print(f\"After filtering battles with unknown models and dupes: {len(battles)} battles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9586bc888c40fa99a0c46c486ada3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/260286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing snapshot for 2023-05-01 (took 36.0s)\n",
      "Storing snapshot for 2023-06-01 (took 36.0s)\n",
      "Storing snapshot for 2023-07-01 (took 35.9s)\n",
      "Storing snapshot for 2023-08-01 (took 35.9s)\n",
      "Storing snapshot for 2023-09-01 (took 36.4s)\n",
      "Storing snapshot for 2023-10-01 (took 35.9s)\n",
      "Storing snapshot for 2023-11-01 (took 36.0s)\n",
      "Storing snapshot for 2023-12-01 (took 36.4s)\n",
      "Storing snapshot for 2024-01-01 (took 36.5s)\n",
      "Storing snapshot for 2024-02-01 (took 36.6s)\n",
      "Storing snapshot for 2024-03-01 (took 36.8s)\n",
      "Storing snapshot for 2024-04-01 (took 37.1s)\n",
      "Storing snapshot for 2024-05-01 (took 38.1s)\n",
      "Storing snapshot for 2024-06-01 (took 38.2s)\n",
      "Storing snapshot for 2024-07-01 (took 38.6s)\n",
      "Storing snapshot for 2024-08-01 (took 38.8s)\n"
     ]
    }
   ],
   "source": [
    "# Actually create some ratings.\n",
    "\n",
    "ranker = ChoixRankerConfIntervals(\n",
    "    models=models,\n",
    "    num_bootstrap_iterations=10,\n",
    "    choix_ranker_algorithm=\"lsr_pairwise\",\n",
    ")\n",
    "\n",
    "sample_fraction = 0.333\n",
    "battles_sample = battles.sample(frac=sample_fraction).sort_values(by=\"tstamp\", ascending=True)\n",
    "prev_tstamp_datetime = datetime.fromtimestamp(battles_sample.iloc[0].tstamp)\n",
    "for _, row in tqdm(battles_sample.iterrows(), total=len(battles_sample)):\n",
    "    model_a = row.model_a.lower()\n",
    "    model_b = row.model_b.lower()\n",
    "    if row.winner == \"model_a\":\n",
    "        ranker.update(model_a, model_b, 1.0)\n",
    "    elif \"tie\" in row.winner:\n",
    "        ranker.update(model_a, model_b, 0.5)\n",
    "        ranker.update(model_b, model_a, 0.5)\n",
    "    elif row.winner == \"model_b\":\n",
    "        ranker.update(model_b, model_a, 1.0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown winner: {row.winner}\")\n",
    "    tstamp_datetime = datetime.fromtimestamp(row.tstamp)\n",
    "    # Store a snapshot every month.\n",
    "    should_store = prev_tstamp_datetime is None or (\n",
    "        (tstamp_datetime.year, tstamp_datetime.month) != (prev_tstamp_datetime.year, prev_tstamp_datetime.month)\n",
    "    )\n",
    "    if should_store:\n",
    "        start = time()\n",
    "        ranker.to_db(OVERALL_CATEGORY_NAME, snapshot_timestamp=tstamp_datetime)\n",
    "        delta = time() - start\n",
    "        print(f\"Storing snapshot for {tstamp_datetime.strftime('%Y-%m-%d')} (took {delta:.1f}s)\")\n",
    "    prev_tstamp_datetime = tstamp_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ys-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
