{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8a93dc5b67bcbb9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T06:20:01.582826700Z",
     "start_time": "2024-09-05T06:20:01.551189100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "ds = load_dataset(\"allenai/WildChat-1M\")\n",
    "env_local_path = \"../../sarai-chat/.env.local\"\n",
    "load_dotenv(env_local_path)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39ab4bcc202d717f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T05:30:45.345451600Z",
     "start_time": "2024-09-05T05:30:45.299498800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from asyncio import Semaphore\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from tqdm.asyncio import tqdm_asyncio as tqdm_asyncio\n",
    "\n",
    "sem = Semaphore(24)  # 24 concurrent max\n",
    "client = AsyncOpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "async def chat_complete(\n",
    "    user_prompt: str, system_prompt: str = \"\", model: str = \"gpt-4o\", temperature: float = 0, sem: Semaphore = None\n",
    ") -> str:\n",
    "    sem = sem or Semaphore(1)\n",
    "\n",
    "    try:\n",
    "        async with sem:\n",
    "            sys_prefix = [dict(role=\"system\", content=system_prompt)] if system_prompt else []\n",
    "            response = await client.chat.completions.create(\n",
    "                messages=sys_prefix + [dict(role=\"user\", content=user_prompt)], model=model, temperature=temperature\n",
    "            )\n",
    "\n",
    "            return response.choices[0].message.content\n",
    "    except:  # noqa\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "async def batch_complete(prompts: list[str], **kwargs):\n",
    "    return await tqdm_asyncio.gather(*[chat_complete(prompt, sem=sem, **kwargs) for prompt in prompts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f3e4bf56e953285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T05:46:56.881300400Z",
     "start_time": "2024-09-05T05:30:56.760816600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [15:24<00:00, 10.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_persona_prompt(user_messages: list[str]):\n",
    "    message = \"\\n\".join(user_messages)\n",
    "    prompt = f\"\"\"Respond with fewer than 50 words the persona (e.g., scientist, programmer, artist, layman, etc.), interests (e.g., C++, physics, gardening), and writing style (lowercase informal, texting, formal) of this person: {message}\n",
    "    \n",
    "    Return it as a JSON object, e.g., {{\"persona\": ..., \"interests\": [\"...\"], \"style\": ...}}. Do not explain or add markup.\n",
    "    \"\"\"  # noqa\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def switch_role(chat_line: dict[str, str]):\n",
    "    chat_line[\"role\"] = \"user\" if chat_line[\"role\"] == \"assistant\" else \"assistant\"\n",
    "    chat_line = dict(role=chat_line[\"role\"], content=chat_line[\"content\"])\n",
    "    return chat_line\n",
    "\n",
    "\n",
    "num_ft_rows = 10000\n",
    "ft_examples = []\n",
    "personas = []\n",
    "row_idxs = []\n",
    "\n",
    "row_idx = 0\n",
    "\n",
    "while len(row_idxs) < num_ft_rows:\n",
    "    row_idx += 1\n",
    "    row = ds[\"train\"][row_idx]\n",
    "\n",
    "    if row[\"country\"] != \"United States\":\n",
    "        continue\n",
    "\n",
    "    row_idxs.append(row_idx)\n",
    "    personas.append(get_persona_prompt([x[\"content\"] for x in row[\"conversation\"] if x[\"role\"] == \"user\"]))\n",
    "\n",
    "persona_strings = await batch_complete(personas)\n",
    "required_keys = {\"persona\", \"interests\", \"style\"}\n",
    "\n",
    "for row_idx, persona_string in zip(row_idxs, persona_strings, strict=False):\n",
    "    row = ds[\"train\"][row_idx]\n",
    "\n",
    "    try:\n",
    "        persona_data = json.loads(persona_string)\n",
    "\n",
    "        if required_keys.difference(set(persona_data.keys())):\n",
    "            # non-empty; doesn't contain enough keys\n",
    "            continue\n",
    "\n",
    "        ft_conversation = []\n",
    "        ft_conversation.append(dict(role=\"system\", content=json.dumps(persona_data)))\n",
    "        ft_conversation.append(dict(role=\"user\", content=\"Start chatting...\"))\n",
    "        ft_conversation += [switch_role(x) for x in row[\"conversation\"]]\n",
    "\n",
    "        ft_examples.append(ft_conversation)\n",
    "    except:  # noqa\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4d60c8c65988fa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T06:16:12.331367700Z",
     "start_time": "2024-09-05T06:16:12.251934600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "with Path(\"data/fine-tuning-5k.jsonl\").open(\"w\") as f:\n",
    "    for ft_example in ft_examples:\n",
    "        ft_example = ft_example[:-1]  # drop last message, which is not an assistant\n",
    "        print(json.dumps(dict(messages=ft_example)), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e45b5a31795c8908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T06:31:35.801220Z",
     "start_time": "2024-09-05T06:31:35.737926400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fac6362153c12cee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-05T06:26:44.669602400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ret = client.files.create(file=open(\"data/fine-tuning-5k.jsonl\", \"rb\"), purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6acfa1c8c774d5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T06:27:31.194097300Z",
     "start_time": "2024-09-05T06:26:59.182041200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ft_job = client.fine_tuning.jobs.create(training_file=ret.id, model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c589c99a79c39a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T06:31:38.066325700Z",
     "start_time": "2024-09-05T06:31:37.353453Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-H1zgfvNuwjk8MEdvoC7hcoBP', created_at=1725517535, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=9, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=[], seed=1927579229, status='validating_files', trained_tokens=None, training_file='file-0HkpNIAQwZg4nDAP6b9pfTd3', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "FineTuningJob(id='ftjob-NeqHHFppV6WNNwi3AOiWE7el', created_at=1725517026, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=9, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=[], seed=1756357400, status='validating_files', trained_tokens=None, training_file='file-0HkpNIAQwZg4nDAP6b9pfTd3', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "FineTuningJob(id='ftjob-T8kHopIqOKeqtlfTloZEYwtw', created_at=1725516947, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Line 1, key \"messages\": The last message must be from the assistant', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=[], seed=727055140, status='failed', trained_tokens=None, training_file='file-ySj0eteH6kwkiGvZivDAKgrV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "FineTuningJob(id='ftjob-zbwyLZnJR8dNsFkCwogYFFKZ', created_at=1725516554, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 1 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=[], seed=1076223507, status='failed', trained_tokens=None, training_file='file-mDBCCE3vInDuxC9h9KsBbt7C', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "FineTuningJob(id='ftjob-lV9eO5nFfS9AilG3gRnc99AR', created_at=1725516360, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 1 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=[], seed=1819233712, status='failed', trained_tokens=None, training_file='file-mDBCCE3vInDuxC9h9KsBbt7C', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "for job in client.fine_tuning.jobs.list(limit=3):\n",
    "    print(job)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "76e17c0fc42f6661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T06:31:31.107002500Z",
     "start_time": "2024-09-05T06:31:30.823429700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "FineTuningJob(id='ftjob-MNX1SHvY56jUNFTK70MPDOSH', created_at=1725517698, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=9, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=[], seed=332634286, status='validating_files', trained_tokens=None, training_file='file-c7LMnasYXwp8K82ZWpof8LPs', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(ft_job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4a17ec2154297ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T06:32:17.854872800Z",
     "start_time": "2024-09-05T06:32:17.549344Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-B3obcYvWRUJmi9VxmCqVd1L7', created_at=1725517535, level='info', message='Validating training file: file-0HkpNIAQwZg4nDAP6b9pfTd3', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-n1gMrtooOEQGZSfpCFmv8ZqL', created_at=1725517535, level='info', message='Created fine-tuning job: ftjob-H1zgfvNuwjk8MEdvoC7hcoBP', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list_events(\"ftjob-H1zgfvNuwjk8MEdvoC7hcoBP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1dd79e48b945eb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
