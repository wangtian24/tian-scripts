{
 "cells": [
  {
   "cell_type": "code",
   "id": "8a93dc5b67bcbb9d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-15T07:20:28.317497Z",
     "start_time": "2024-09-15T07:20:26.832497Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "ds = load_dataset(\"allenai/WildChat-1M\")\n",
    "env_local_path = \".env.local\"\n",
    "load_dotenv(env_local_path)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "do_persona_ft = False  # if False, we do personaless fine-tuning, which seems to do better\n",
    "filtered_languages = {\"en\"}  # if empty, do not do filtering. Otherwise, include only languages in this set\n",
    "filtered_countries = {\"United States\", \"Canada\", \"United Kingdom\", \"New Zealand\", \"Australia\"}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "39ab4bcc202d717f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-15T07:20:33.441296Z",
     "start_time": "2024-09-15T07:20:32.909247Z"
    }
   },
   "source": [
    "from asyncio import Semaphore\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from tqdm.asyncio import tqdm_asyncio as tqdm_asyncio\n",
    "\n",
    "sem = Semaphore(24)  # 24 concurrent max\n",
    "client = AsyncOpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "async def chat_complete(\n",
    "    user_prompt: str, system_prompt: str = \"\", model: str = \"gpt-4o\", temperature: float = 0, sem: Semaphore = None\n",
    ") -> str:\n",
    "    sem = sem or Semaphore(1)\n",
    "\n",
    "    try:\n",
    "        async with sem:\n",
    "            sys_prefix = [dict(role=\"system\", content=system_prompt)] if system_prompt else []\n",
    "            response = await client.chat.completions.create(\n",
    "                messages=sys_prefix + [dict(role=\"user\", content=user_prompt)], model=model, temperature=temperature\n",
    "            )\n",
    "\n",
    "            return response.choices[0].message.content\n",
    "    except:  # noqa\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "async def batch_complete(prompts: list[str], **kwargs):\n",
    "    return await tqdm_asyncio.gather(*[chat_complete(prompt, sem=sem, **kwargs) for prompt in prompts])"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "a9952bfcad4a8b53",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-15T07:20:37.220677Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_persona_prompt(user_messages: list[str]):\n",
    "    message = \"\\n\".join(user_messages)\n",
    "    prompt = f\"\"\"Respond with fewer than 50 words the persona (e.g., scientist, programmer, artist, layman, etc.), interests (e.g., C++, physics, gardening), and writing style (lowercase informal, texting, formal) of this person: {message}\n",
    "    \n",
    "    Return it as a JSON object, e.g., {{\"persona\": ..., \"interests\": [\"...\"], \"style\": ...}}. Do not explain or add markup.\n",
    "    \"\"\"  # noqa\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def switch_role(chat_line: dict[str, str]):\n",
    "    chat_line[\"role\"] = \"user\" if chat_line[\"role\"] == \"assistant\" else \"assistant\"\n",
    "    chat_line = dict(role=chat_line[\"role\"], content=chat_line[\"content\"])\n",
    "    return chat_line\n",
    "\n",
    "\n",
    "num_ft_rows = 300000\n",
    "rows = ds[\"train\"].shuffle()[:num_ft_rows]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43135280cb1c1099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T05:45:40.067650Z",
     "start_time": "2024-09-14T05:45:39.360623Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61b9a1e2119226",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T05:45:40.234210Z",
     "start_time": "2024-09-14T05:45:40.068725Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdf = df.groupby(\"hashed_ip\")\n",
    "df = gdf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b2d813711b1be24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T05:53:38.775007Z",
     "start_time": "2024-09-14T05:53:31.449329Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224492it [00:07, 30666.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from fast_langdetect import detect\n",
    "from tqdm import tqdm\n",
    "\n",
    "ft_examples = []\n",
    "personas = []\n",
    "filt_rows = []\n",
    "filt_user_texts = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    if filtered_countries and row[\"country\"] not in filtered_countries:\n",
    "        continue\n",
    "\n",
    "    user_text = \"\\n\".join(x[\"content\"] for x in row[\"conversation\"] if x[\"role\"] == \"user\")\n",
    "\n",
    "    try:\n",
    "        lang = detect(user_text)\n",
    "    except:  # noqa\n",
    "        continue\n",
    "\n",
    "    lang = lang[\"lang\"]\n",
    "\n",
    "    if filtered_languages and lang not in filtered_languages:\n",
    "        continue\n",
    "\n",
    "    personas.append(get_persona_prompt([x[\"content\"] for x in row[\"conversation\"] if x[\"role\"] == \"user\"]))\n",
    "    filt_rows.append(row)\n",
    "    filt_user_texts.append(row[\"conversation\"][0][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72416c75672c3e81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T05:55:05.291849Z",
     "start_time": "2024-09-14T05:54:49.422470Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\").cuda()\n",
    "user_vecs = model.encode(filt_user_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4bba72c209e401c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:04:59.685606Z",
     "start_time": "2024-09-14T06:04:08.840968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff 1.0082007086277007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15360it [00:50, 302.18it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sel_vec_idxs = []\n",
    "cutoff = np.quantile(np.linalg.norm(user_vecs[:5000] - user_vecs[5000:10000], axis=1), 0.01)\n",
    "print(\"Dedup cutoff\", cutoff)\n",
    "\n",
    "for idx, user_vec in tqdm(enumerate(user_vecs)):\n",
    "    sel = True\n",
    "\n",
    "    for sel_vec_idx in sel_vec_idxs:\n",
    "        if np.linalg.norm(user_vecs[sel_vec_idx] - user_vec) < cutoff:\n",
    "            sel = False\n",
    "            break\n",
    "\n",
    "    if sel:\n",
    "        sel_vec_idxs.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be89dd1c8fdaf11e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:09:11.877446Z",
     "start_time": "2024-09-14T06:09:11.763086Z"
    }
   },
   "outputs": [],
   "source": [
    "filt_new_rows = np.array(filt_rows, dtype=object)[sel_vec_idxs].tolist()\n",
    "new_personas = np.array(personas, dtype=object)[sel_vec_idxs].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f3e4bf56e953285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:09:56.039404Z",
     "start_time": "2024-09-14T06:09:55.967419Z"
    }
   },
   "outputs": [],
   "source": [
    "if do_persona_ft:\n",
    "    persona_strings = await batch_complete(new_personas)\n",
    "else:\n",
    "    persona_strings = [\"{}\"] * len(filt_new_rows)\n",
    "\n",
    "required_keys = {\"persona\", \"interests\", \"style\"}\n",
    "\n",
    "for row, persona_string in zip(filt_new_rows, persona_strings, strict=False):\n",
    "    try:\n",
    "        persona_data = json.loads(persona_string)\n",
    "\n",
    "        if do_persona_ft and required_keys.difference(set(persona_data.keys())):\n",
    "            # non-empty; doesn't contain enough keys\n",
    "            continue\n",
    "\n",
    "        ft_conversation = []\n",
    "\n",
    "        if do_persona_ft:\n",
    "            ft_conversation.append(dict(role=\"system\", content=json.dumps(persona_data)))\n",
    "\n",
    "        ft_conversation.append(dict(role=\"user\", content=\"Start chatting...\"))\n",
    "        ft_conversation += [switch_role(x) for x in row[3]]\n",
    "\n",
    "        ft_examples.append(ft_conversation)\n",
    "    except:  # noqa\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97bc159d84453165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:09:57.610916Z",
     "start_time": "2024-09-14T06:09:57.607260Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6240"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ft_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4d60c8c65988fa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:10:06.667826Z",
     "start_time": "2024-09-14T06:10:06.593098Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_name = \"data/personaless-fine-tuning-clean-6k.jsonl\"\n",
    "\n",
    "with Path(output_name).open(\"w\") as f:\n",
    "    for ft_example in ft_examples:\n",
    "        ft_example = ft_example[:-1]  # drop last message, which is not an assistant\n",
    "        print(json.dumps(dict(messages=ft_example)), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e45b5a31795c8908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:13:22.543998Z",
     "start_time": "2024-09-14T06:13:22.536017Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "output_name = \"data/personaless-fine-tuning-clean-clean-6k.jsonl\"\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fac6362153c12cee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:13:30.649521Z",
     "start_time": "2024-09-14T06:13:26.471701Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ret = client.files.create(file=open(output_name, \"rb\"), purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6acfa1c8c774d5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:14:00.019841Z",
     "start_time": "2024-09-14T06:13:58.840202Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "ft_job = client.fine_tuning.jobs.create(\n",
    "    training_file=ret.id, model=\"gpt-4o-mini-2024-07-18\", hyperparameters=dict(n_epochs=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c589c99a79c39a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:14:26.026766Z",
     "start_time": "2024-09-14T06:14:25.363338Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-5BVZ98vdyUMEoLLLBCNy8Zi9', created_at=1726294435, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=2, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=[], seed=1525065784, status='validating_files', trained_tokens=None, training_file='file-24JsIyrbW2HBWU8aHWrN4Boz', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "FineTuningJob(id='ftjob-0jGeCaBGHfz5s2S3VD2ZGLdU', created_at=1726276803, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:yupp::A7DE2LPf', finished_at=1726282496, hyperparameters=Hyperparameters(n_epochs=2, batch_size=15, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=['file-LKQvBqoBwqZFAXiCGsmvTcK7'], seed=1514565278, status='succeeded', trained_tokens=19026816, training_file='file-d08ozP8LrXrsvmyp7Icgwvl6', validation_file=None, estimated_finish=1726291871, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "FineTuningJob(id='ftjob-VLo5O35TXlX2JBxaddl5evwl', created_at=1726267678, error=Error(code='invalid_training_file', message=\"The job failed due to an invalid training file. This training file was blocked by our moderation system because it contains too many examples that violate OpenAI's usage policies, or because it attempts to create model outputs that violate OpenAI's usage policies.\", param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=2, batch_size=16, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=[], seed=321245833, status='failed', trained_tokens=None, training_file='file-1wsfL1g1DOcWXLgfWHXBC1xj', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "FineTuningJob(id='ftjob-eOwdP9oEI9GwdLMAYz4W9ZnX', created_at=1726267367, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Example 9969 message contains an invalid token: <|endoftext|>.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=2, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=[], seed=1748000754, status='failed', trained_tokens=None, training_file='file-letL49cWCDNWkwk87tkBPWe9', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "FineTuningJob(id='ftjob-SzBTqHH2wDSMiSWYe2qrs1LV', created_at=1726163389, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:yupp::A6lsosEF', finished_at=1726177393, hyperparameters=Hyperparameters(n_epochs=2, batch_size=66, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=['file-O2SbCDjWtESJxqh9nDEKNl8q'], seed=396478088, status='succeeded', trained_tokens=64045556, training_file='file-aZSF1dPHLkgScMPejZGU39vr', validation_file=None, estimated_finish=1726290068, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "FineTuningJob(id='ftjob-QhUb55MhAh2iTDEvmfTKnCN7', created_at=1726161758, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=1, batch_size=33, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=[], seed=748806018, status='cancelled', trained_tokens=None, training_file='file-aZSF1dPHLkgScMPejZGU39vr', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "FineTuningJob(id='ftjob-PJWyYjx54PupbS4CphS0iwi0', created_at=1725600737, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:yupp::A4NbyYPo', finished_at=1725607437, hyperparameters=Hyperparameters(n_epochs=2, batch_size=19, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=['file-a58ENcLj9FANPqUPEERoV9OQ'], seed=259481143, status='succeeded', trained_tokens=20935948, training_file='file-Ii4eArQWPo9jpvKNalWsZ6WG', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "FineTuningJob(id='ftjob-MNX1SHvY56jUNFTK70MPDOSH', created_at=1725517698, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:yupp::A419huyw', finished_at=1725521116, hyperparameters=Hyperparameters(n_epochs=3, batch_size=9, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=['file-Ve9RXjrpszJnhOhV8FN92lWt'], seed=332634286, status='succeeded', trained_tokens=6688398, training_file='file-c7LMnasYXwp8K82ZWpof8LPs', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for job in client.fine_tuning.jobs.list(limit=3):\n",
    "    print(job)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "76e17c0fc42f6661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T06:31:31.107002500Z",
     "start_time": "2024-09-05T06:31:30.823429700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-MNX1SHvY56jUNFTK70MPDOSH', created_at=1725517698, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=9, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-3ASX67KsWNwPQahmhfe6g8KT', result_files=[], seed=332634286, status='validating_files', trained_tokens=None, training_file='file-c7LMnasYXwp8K82ZWpof8LPs', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(ft_job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4a17ec2154297ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T06:32:17.854872800Z",
     "start_time": "2024-09-05T06:32:17.549344Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-B3obcYvWRUJmi9VxmCqVd1L7', created_at=1725517535, level='info', message='Validating training file: file-0HkpNIAQwZg4nDAP6b9pfTd3', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-n1gMrtooOEQGZSfpCFmv8ZqL', created_at=1725517535, level='info', message='Created fine-tuning job: ftjob-H1zgfvNuwjk8MEdvoC7hcoBP', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list_events(\"ftjob-H1zgfvNuwjk8MEdvoC7hcoBP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1dd79e48b945eb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
