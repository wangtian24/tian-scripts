{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81efc08f-0615-4cd0-be91-a79699708339",
   "metadata": {},
   "source": [
    "# Quicktake Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93792f9fdef9b88d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T22:52:37.674213800Z",
     "start_time": "2024-08-29T22:52:37.655507200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "env_local_path = \"../../sarai-chat/.env.local\"\n",
    "load_dotenv(env_local_path)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7dc85068-902f-4da4-a37d-f12abe3ab405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T00:05:11.216930Z",
     "start_time": "2024-08-30T00:05:11.170262900Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI(api_key=api_key)\n",
    "old_sys_prompt = \"\"\"you are a model that will give very quick responses. IMPORTANT: don't add any explanations on the answer. don't write full sentences, unless the user is very specifically asking you for a long answer. for answers that are non-factual, make it witty or funny, but still brief.\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "Question: Why is the sky blue?\n",
    "Answer: Rayleigh scattering of sunlight by the atmosphere.\n",
    "\n",
    "Question: what is the meaning of life?\n",
    "Answer: 42\n",
    "\n",
    "Question: How many people are there in the US?\n",
    "Answer: 333.3 million\n",
    "\n",
    "Question: Should I buy Elden Ring?\n",
    "Answer: Only if you enjoy gorgeous landscapes and repeatedly dying in them\n",
    "\"\"\"  # noqa\n",
    "\n",
    "new_sys_prompt = \"\"\"You are a model that will give very concise responses. IMPORTANT: don't add any explanations on the answer; don't write full sentences, unless the user is very specifically asking you for a long answer; for answers that are non-factual, make it witty or funny, but still brief; if the user asks to output markdown or any markup, return the cleaned text only; do not use newlines; NEVER prompt for more information, feedback, or responses. Respond in fewer than 160 characters. Return \"NULL\" (without quotes) if additional user input must be provided for a response, or if you can't satisfy the constraints. If it is too long or complex or if you have to apologize, also return \"NULL\".\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "Question: Why is the sky blue?\n",
    "Answer: Rayleigh scattering of sunlight by the atmosphere.\n",
    "\n",
    "Question: what is the meaning of life?\n",
    "Answer: 42\n",
    "\n",
    "Question: How many people are there in the US?\n",
    "Answer: 333.3 million\n",
    "\n",
    "Question: Should I buy Elden Ring?\n",
    "Answer: Only if you enjoy gorgeous landscapes and repeatedly dying in them\n",
    "\"\"\"  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52347e3c5d1df00f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T22:55:47.069391300Z",
     "start_time": "2024-08-29T22:55:43.905756Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"allenai/WildChat-1M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "352227032f7f42d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T23:24:04.778793300Z",
     "start_time": "2024-08-29T23:24:04.485082300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rand_rows = 200\n",
    "user_prompts = []\n",
    "assistant_responses = []\n",
    "rand_idxs = np.random.permutation(len(ds[\"train\"]))[:rand_rows]\n",
    "\n",
    "for idx in rand_idxs:\n",
    "    conversation = ds[\"train\"][int(idx)][\"conversation\"]\n",
    "\n",
    "    try:\n",
    "        assistant_responses.append(conversation[1][\"content\"])\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "    user_prompts.append(conversation[0][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1d5de05bdcd3afe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T23:26:41.681185900Z",
     "start_time": "2024-08-29T23:26:41.681185900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from asyncio import Semaphore\n",
    "\n",
    "\n",
    "async def chat_complete(\n",
    "    user_prompt: str, system_prompt: str = \"\", model: str = \"gpt-4o\", temperature: float = 0, sem: Semaphore = None\n",
    ") -> str:\n",
    "    sem = sem or Semaphore(1)\n",
    "\n",
    "    try:\n",
    "        async with sem:\n",
    "            sys_prefix = [dict(role=\"system\", content=system_prompt)] if system_prompt else []\n",
    "            response = await client.chat.completions.create(\n",
    "                messages=sys_prefix + [dict(role=\"user\", content=user_prompt)], model=model, temperature=temperature\n",
    "            )\n",
    "\n",
    "            return response.choices[0].message.content\n",
    "    except:  # noqa\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "49de6f41fd1b90ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T23:24:11.217874700Z",
     "start_time": "2024-08-29T23:24:11.122024500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "input_lengths = []\n",
    "output_lengths = []\n",
    "\n",
    "for prompt, response in zip(user_prompts, assistant_responses, strict=False):\n",
    "    input_lengths.append(len(encoding.encode(prompt)))\n",
    "    output_lengths.append(len(encoding.encode(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8457bc7c14f8751b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T23:24:12.030534700Z",
     "start_time": "2024-08-29T23:24:12.014909Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(335.59, 361.52)"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(input_lengths), np.mean(output_lengths)  # Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f904481c1d8e01d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T23:26:45.358488100Z",
     "start_time": "2024-08-29T23:26:45.327071200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm.asyncio import tqdm_asyncio as tqdm_asyncio\n",
    "\n",
    "sem = Semaphore(5)  # 5 concurrent max\n",
    "\n",
    "\n",
    "async def batch_complete(prompts: list[str], **kwargs):\n",
    "    return await tqdm_asyncio.gather(*[chat_complete(prompt, sem=sem, **kwargs) for prompt in prompts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e22a3bc3c6bf2f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_tldr_responses = await batch_complete(\n",
    "    user_prompts, model=\"gpt-4-turbo\", system_prompt=old_sys_prompt, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08fef259493ba8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_tldr_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1d5e814ebfde8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_tldr_responses = await batch_complete(\n",
    "    user_prompts, model=\"gpt-4-turbo\", system_prompt=new_sys_prompt, temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe8b743d9fd0f8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_tldr_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b84899d61743deba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T00:31:50.862969800Z",
     "start_time": "2024-08-30T00:31:49.428485200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1d5f260ffee11dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T03:57:10.627875400Z",
     "start_time": "2024-08-30T03:57:10.582716900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save((user_prompts, old_tldr_responses, new_tldr_responses), \"data/tldr_responses.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9b681b9e837ad1a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:03:52.571933400Z",
     "start_time": "2024-08-30T04:03:52.523611300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dict(user_prompt=user_prompts, old_response=old_tldr_responses, new_response=new_tldr_responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e5bf921d06a7a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dc80cb4cc6679585",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:05:45.837143900Z",
     "start_time": "2024-08-30T04:05:45.004399100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import langdetect\n",
    "\n",
    "df[\"language\"] = [langdetect.detect(x) for x in df.user_prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "40f72ecc02fd5b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:06:02.846281500Z",
     "start_time": "2024-08-30T04:06:02.799575300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df.language == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9854be176437f69a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:08:07.966578700Z",
     "start_time": "2024-08-30T04:08:07.901735200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/tldr_analysis.tsv\", sep=\"\\t\", quoting=3, escapechar=\"\\\\\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af66eb987570cb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1861d77a5614c1b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:17:24.375742700Z",
     "start_time": "2024-08-30T04:17:24.310333300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Wayne Booth advocated for rhetoric as a peaceful alternative to violence, emphasizing ethical language use and listening for mutual understanding. His ideas resonate in various social and political contexts, highlighting the power of thoughtful communication in addressing conflicts and fostering change.'"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[100].new_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "134b7662f46d2211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:21:28.732570700Z",
     "start_time": "2024-08-30T04:21:28.683648200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({-1: 40, 1: 25, 0: 8})"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# These are unblinded self-annotations\n",
    "ctr = Counter({-1: 40, 1: 25, 0: 8})\n",
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "516a9ea90105d1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T18:09:35.066609200Z",
     "start_time": "2024-08-30T18:09:11.233973900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:23<00:00,  4.62it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_prompt = \"\"\"Prompt: {user_prompt}\n",
    "\n",
    "(1) {first_response}\n",
    "(2) {second_response}\n",
    "\n",
    "Which is a better summarized response to the prompt? Empty means that no good summarization exists, which is better than apologizing, refusing to answer (e.g., this is too hard or complex), asking for more information (e.g., please provide more information), seeming odd given the prompt (e.g., flippant or offensive), or being verbose. If one contains markdown or markup, asks for more information, refuses to answer (says it is too complex), seems flippant, it is bad; pick the other. Say (1) for the first and (2) for the second. If they are equally good (or bad), say \"3\". Do not explain.\"\"\"  # noqa\n",
    "\n",
    "ctr = Counter()\n",
    "random.seed(0)\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    responses = [row.old_response, row.new_response.replace(\"NULL\", \"\")]\n",
    "    do_swap = random.random() < 0.5  # We randomly swap to reduce order sensitivity\n",
    "\n",
    "    if do_swap:\n",
    "        responses = responses[::-1]\n",
    "\n",
    "    prompt = test_prompt.format(first_response=responses[0], second_response=responses[1], user_prompt=row.user_prompt)\n",
    "\n",
    "    if \"\\n\" in row.old_response or (len(row.old_response) > 160 and len(row.new_response) <= 160):\n",
    "        is_new_better = True\n",
    "        is_tie = False\n",
    "    else:\n",
    "        judgement = await chat_complete(prompt)\n",
    "        is_new_better = \"0\" in judgement if do_swap else \"1\" in judgement\n",
    "        is_tie = \"3\" in judgement\n",
    "\n",
    "    if is_tie:\n",
    "        ctr[-1] += 1\n",
    "    elif is_new_better:\n",
    "        ctr[1] += 1\n",
    "    else:\n",
    "        ctr[0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3490c465a9327882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T18:09:40.051013600Z",
     "start_time": "2024-08-30T18:09:40.051013600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({1: 59, 0: 33, -1: 18})"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6a2896cd41888f9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T18:09:42.538378200Z",
     "start_time": "2024-08-30T18:09:42.511227200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.16363636363636364"
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of ties\n",
    "ctr[-1] / sum(ctr.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "66fbd20531a88908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T18:09:43.792602500Z",
     "start_time": "2024-08-30T18:09:43.745730Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(0.6413043478260869, 110)"
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preference for the new tl;dr prompt\n",
    "ctr[1] / (ctr[0] + ctr[1]), sum(ctr.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "27a775f11fb4c575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T18:09:45.320790400Z",
     "start_time": "2024-08-30T18:09:45.315285800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.11818181818181815"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Absolute improvement (accounting for ties)\n",
    "(ctr[1] / (ctr[0] + ctr[1]) - 0.5) * (1 - ctr[-1] / sum(ctr.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "454048919fda4584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T18:09:51.206231300Z",
     "start_time": "2024-08-30T18:09:51.143690300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(0.5345667461484916, 0.7386707617060246)"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.stats.proportion\n",
    "\n",
    "# 95% CI\n",
    "statsmodels.stats.proportion.proportion_confint(ctr[1], ctr[0] + ctr[1], method=\"beta\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
