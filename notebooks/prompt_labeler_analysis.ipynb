{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 2100\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "from sqlmodel import Session\n",
    "\n",
    "from ypl.backend.db import get_engine\n",
    "\n",
    "raw_query = text(f\"\"\"\n",
    "SELECT DISTINCT content FROM (\n",
    "SELECT \n",
    "    cm.content, \n",
    "    EXTRACT(DAY FROM (NOW() - cm.created_at)) AS age\n",
    "FROM chat_messages cm\n",
    "WHERE cm.message_type = 'USER_MESSAGE'\n",
    "  AND cm.created_at > NOW() - INTERVAL '8 weeks'\n",
    "  AND array_length(regexp_split_to_array(cm.content, '\\s+'), 1) > 3\n",
    "  AND cm.content <> 'test'\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 3000\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "with Session(get_engine()) as session:\n",
    "    comp_results = session.exec(raw_query).fetchall()\n",
    "\n",
    "print(f\"Number of results: {len(comp_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(comp_results, columns=[\"content\"])\n",
    "# df = df.sort_values(\"created_at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS_FILE=\"/Users/wangtian/tmp/prompts.txt\"\n",
    "df.to_csv(PROMPTS_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                 start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text',\n",
       "  '    ifstream file(fileName, ios::binary);\\n    if (!file) {\\n        cout << \"Failed to open file.\\\\n\";\\n        return;\\n    }\\n\\n    vector<string> chunks;\\n    char buffer[CHUNK_SIZE];\\n    int chunkID = 0;\\n\\n    while (file.read(buffer, CHUNK_SIZE) || file.gcount() > 0) {\\n        string chunk(buffer, file.gcount());\\n        string chunkName = fileName + \"_chunk\" + to_string(chunkID++);\\n        chunks.push_back(chunkName);\\n\\n        auto availableNodes = server.getAvailableNodes(world_size);\\n        if (availableNodes.size() < 3) {\\n            cout << \"Not enough nodes available for replication.\\\\n\";\\n            return;\\n        }\\n\\n        vector<int> selectedNodes(availableNodes.begin(), availableNodes.begin() + 3);\\n        server.chunkToNodes[chunkName] = selectedNodes;\\n\\n        for (int node : selectedNodes) {\\n            server.assignTask(node, \"UPLOAD\", chunkName);  // Assign upload task\\n        }\\n    }\\n\\nexplain the code ignore the metadataserver parts, I only want the file reading parts',\n",
       "  ' hows it going tell me a joke',\n",
       "  ' https://www.youtube.com/watch?v=ojULkWEUsPs&pp=ygUUd2hvIGxldCB0aGUgZG9ncyBvdXQ%3D\\nwhat is happening here.',\n",
       "  ' tell me about your story',\n",
       "  '\"Materials.\\n\\nChemicals were purchased from Sigma/Aldrich/Fluka (Zwijndrecht, The Netherlands) and Acros (Landsmeer, The Netherlands). MMA was distilled at atmospheric pressure and stored at 20 1C. The monomer 4IEMA was synthesized from 4-iodobenzoyl chloride as described previously [16]. MAA, benzoyl peroxide (BPO), tetraethylene glycol dimethacrylate (TEGDMA), poly(vinyl alcohol) (PVA; MW 86000; 99–100% hydrolyzed), poly(ethylene glycol (PEG; MW 1000) and poly(vinyl pyrrolidone) (PVP; K-23–32; MW 5800) were used as purchased. Cell culture medium (DMEM/F12), fetal bovine serum, and antibiotics were from Invitrogen (Breda, The Netherlands). The fluorescent thrombin-specific substrate Z-Gly-Gly-Arg-AMC was from Bachem (Weil am Rhein, Germany). Thrombin with high specific activity (42000 U/mg solid) was purchased from Synapse (BV Maastricht, The Netherlands) and thrombin with low specific activity (43 U/mg solid) was purchased from Sigma. \\nPreparation of microspheres. A solution of PVA (1.25 g), PEG (1.50 g) and PVP (0.25 g) in 100 mL distilled water was magnetically stirred and heated to 85 1C. MMA, 4IEMA, MAA, BPO and TEGDMA were mixed, and this mixture was added dropwise to the stirred aqueous PVA– PEG–PVP solution [25]. After the addition, stirring at 85 1C was continued for 6 h. The microspheres precipitated immediately as stirring was stopped, and the supernatant was decanted carefully. The microspheres were allowed to cool to room temperature, and washed several times in water. In the end, microspheres were frozen (196 1C, liquid nitrogen), and lyophilized. Two types of spheres were prepared: (i) 10% I, containing 10%w/w iodine, consisting of MMA (2.312 g, 23.09 mmol), 4IEMA (1.700 g, 4.72 mmol), MAA (1.988 g, 23.09 mmol), 1 mol% BPO and 2 mol% TEGDMA; and (ii) 20% I, containing 20%w/w iodine, consisting of MMA (1.26 g, 12.55 mmol), 4IEMA (3.402 g, 9.45 mmol), MAA (1.54 g, 17.95 mmol), 1 mol% BPO and 2 mol% TEGDMA. Microspheres were examined by scanning electron microscopy (SEM) using a Philips XL30 SEM system. \\nCytocompatibility. Mouse 3T3 fibroblasts were grown in Dulbecco’s modification of Eagle’s medium/F-12 nutrient mix containing Glutamax-I and supplemented with 10% fetal bovine serum and antibiotic/antimycotic solution (100 U/mL penicillin, 100 mg/mL streptomycin, 0.25 mg/mL amphotericin B). Cells were harvested and 10,000 cells were inoculated in each well of a 24-well plate. The cells were cultured at 37 1C/5% CO2 for 20 h before microspheres were added. Microspheres were sterilized with UV light for 15 min and subsequently were added to the cells in such a way that estimated 20% coverage of the total area by the spheres was achieved. Latex was used as a positive, toxic, control. After 5 days of incubation, photographs of the cells were taken using a Leica DM-IL inverted microscope. From a separate plate, the medium was removed and replaced with culture medium containing 0.5 mg/mL MTT to measure cell viability [26]. The cells were incubated for 1 h at 37 1C, the medium was removed, and the precipitated formazan was dissolved in isopropanol. The absorbance at 550 nm of the samples was determined using a micro-plate reader.\\n X-ray visibility. For demonstration of radiopacity of the microspheres, a realistic model under routine hospital conditions was used. Microspheres were inserted into a rabbit cadaver in two ways: (1) 25 mg loose spheres were inserted into the back muscle and (2) 75 mg spheres were resuspended in 3% gelatin and inserted into the back leg. X-ray pictures were taken using a mammography imaging system (Bennet Trex Medical). \\nImmobilization of thrombin. \\nThe microspheres were washed in 50 mM MES buffer, pH 5.5 for 30 min, resuspended in 20 mM 1-ethyl-3-(3- dimethylaminopropyl)carbodiimide (EDC) and 50 mM N-hydroxysuccinimide (NHS) in 50 mM MES, and incubated at room temperature for 30 min under continuous mixing [27]. Then microspheres were washed once with 50 mM MES and 700 mL thrombin solution was added. For determining the optimal composition of the microspheres, 2.5 mg/mL thrombin with low specific activity was used because of economical reasons. For the following experiments, thrombin of a high quality, 42000 U/mg, was used at a concentration of 0.4 mg/mL. The thrombin was dissolved in thrombin-coupling buffer (50 mM Hepes, 150 mM NaCl pH 8.2). After 2 h incubation at room temperature, spheres were washed at least 6 times in thrombin-coupling buffer. About 10 mg microspheres (in triplo) were put into a 96-well plate and 120 mL thrombin-assay buffer (20 mM Hepes, 150 mM NaCl, 5 mM CaCl2 pH 7.4) was added to each well with spheres. The plate was warmed to 37 1C and 80 mL 1mM fluorescent ARTICLE IN PRESS 2458 K. Saralidze et al. / Biomaterials 28 (2007) 2457–2464 thrombin-substrate, in thrombin-assay buffer, was added to start the quantification of thrombin. Fluorescence increase (ex 368 nm/em 460 nm) was determined with a Gemini XS fluorometer. The increase in fluorescence is directly related to thrombin activity. The amount of coupled thrombin could be estimated by comparison to a standard curve with known amounts of thrombin. \\nMicrosphere induced fibrin formation. Blood was obtained from a healthy donor by venipuncture and mixed with 0.13 M Na-citrate (9 parts blood: 1 part Na-citrate). Platelet rich plasma (PRP) was prepared by centrifugation of blood at 180 g for 15 min. PRP was recalcified by addition of 40 mL/mL 0.5 M CaCl2. Microspheres were incubated at room temperature with recalcified PRP in a 35 mm Petri-dish. The dishes were gently shaken and photographs were taken at regular intervals on a Nikon Eclipse 800 microscope equipped with a RS Photometric CoolSnap digital camera. Aggregates of microspheres that were formed after 2–3 min of incubation in PRP were fixed in 2.5% glutaraldehyde in phosphate buffered saline (pH 7.4) at 4 C. The samples were extensively washed and dried, attached on a stub with double-sided carbon tape, sputter-coated with gold and examined by SEM. \\nMicrosphere induced thrombin generation. To test the ability of the covalently coupled thrombin to induce blood coagulation, microspheres were mixed with recalcified whole blood, PRP, or platelet poor plasma (PPP) that was prepared by centrifugation of blood at 1800g for 10 min. Recalcified blood, PRP, or PPP was added to 10 mg microspheres to start the reaction, which was allowed to proceed at 37 1C. Samples (17.5 mL) were taken every minute and added to 282.5 mL thrombin-stop buffer (20 mM Hepes pH 7.4, 140 mM NaCl, 20 mM EDTA, 1 mg/mL BSA, 200 mM S2238). EDTA was used to directly abolish any further thrombin formation by binding all available calcium, S2238 is a chromogenic thrombin-specific substrate. Sampling was stopped upon complete clotting of the blood, PRP or PPP. In the case of incubation with whole blood, erythrocytes were removed by short centrifugation (5 s) and the supernatant was pipetted into a 96-well microplate. The plate was heated to 37 C and increase in extinction at 405 nm could be directly converted to thrombin concentration. For PRP and PPP samples, no centrifugation was needed, and so the samples could be measured directly in a 96-well microplate. Also spheres without coupled thrombin (control spheres) were used as well as the empty tube. The concentration of thrombin was plotted against time.\" how can I adapt this methodology, to this task? : During this task you will covalently couple you isolated amylase from task 1 to the plastic\\nparticles (NIPs) from task 2.',\n",
       "  '1 + 1 ?',\n",
       "  '1 word from each pdf',\n",
       "  '1+1 in step by step',\n",
       "  '150 hourly rate to salary'],\n",
       " 2100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = df[\"content\"].tolist()\n",
    "\n",
    "# Write prompts to file, escaping newlines to preserve one-prompt-per-line format\n",
    "with open(PROMPTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    for prompt in prompts:\n",
    "        # Replace newlines with \\n escape sequence and write\n",
    "        escaped_prompt = prompt.replace(\"\\n\", \"\\\\n\")\n",
    "        f.write(escaped_prompt + \"\\n\")\n",
    "\n",
    "# Return original tuple for notebook display\n",
    "prompts[:10], len(prompts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all results from a local server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "from typing import Any\n",
    "\n",
    "CLASSIFY_PROMPT_ENDPOINT = \"http://localhost:8000/api/v1/classify/prompt\"\n",
    "def fetch_classifications(prompt: str, model_name: str | None = None) -> dict[str, Any]:\n",
    "    response = requests.post(\n",
    "        CLASSIFY_PROMPT_ENDPOINT,\n",
    "        params={\"prompt\": prompt, \"model_name\": model_name},\n",
    "        headers={\"X-API-KEY\": \"\"},\n",
    "    )\n",
    "    return dict(response.json())\n",
    "\n",
    "def classify_with_model_parallel(prompts: list[str], model_name: str | None = None, max_workers: int = 30) -> list[tuple[str, list[str], list[str]]]:\n",
    "    results: list[tuple[str, list[str], list[str]]] = []\n",
    "    # Create a ThreadPoolExecutor with a maximum of 5 workers.\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all HTTP calls concurrently.\n",
    "        future_to_prompt = {\n",
    "            executor.submit(fetch_classifications, prompt, model_name): prompt\n",
    "            for prompt in prompts\n",
    "        }\n",
    "        # As each future completes, gather the result.\n",
    "        from tqdm import tqdm\n",
    "        import threading\n",
    "        import numpy as np\n",
    "        latencies = []\n",
    "        latencies_lock = threading.Lock()\n",
    "        for future in tqdm(concurrent.futures.as_completed(future_to_prompt), total=len(prompts), desc=f\"Processing with {model_name or 'default'}\"):\n",
    "            prompt = future_to_prompt[future]\n",
    "            try:\n",
    "                resp = future.result()\n",
    "                results.append((prompt, resp[\"categories\"], resp[\"modifiers\"]))\n",
    "                total_ms = resp[\"debug_info\"][\"latency_ms\"][\"TOTAL\"]\n",
    "                with latencies_lock:\n",
    "                    latencies.append(total_ms)\n",
    "            except Exception as exc:\n",
    "                print(f\"Prompt {prompt} generated an exception: {exc}\")\n",
    "        \n",
    "        # Compute latency statistics\n",
    "        if latencies:\n",
    "            avg_latency = np.mean(latencies)\n",
    "            p50_latency = np.percentile(latencies, 50)\n",
    "            p90_latency = np.percentile(latencies, 90)\n",
    "            p90_latency = np.percentile(latencies, 95)\n",
    "            p90_latency = np.percentile(latencies, 99)\n",
    "            print(f\"Latency stats for {model_name or 'default'}: avg={avg_latency:.2f}ms, p50={p50_latency:.2f}ms, p90={p90_latency:.2f}ms, p95={p90_latency:.2f}ms, p99={p90_latency:.2f}ms\")\n",
    "    \n",
    "    return sorted(results, key=lambda x: x[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with gemini-1.5-flash-8b:  35%|███▍      | 733/2100 [00:12<00:22, 60.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the classifier for before and after\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m before = \u001b[43mclassify_with_model_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-1.5-flash-8b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m                  \u001b[38;5;66;03m# None means default, current is gpt-4o-mini\u001b[39;00m\n\u001b[32m      4\u001b[39m after = classify_with_model_parallel(prompts, \u001b[33m\"\u001b[39m\u001b[33mgemini-2.0-flash-001\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m      5\u001b[39m after1 = classify_with_model_parallel(prompts, \u001b[33m\"\u001b[39m\u001b[33mMeta-Llama-3.3-70B-Instruct\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# sambanova\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mclassify_with_model_parallel\u001b[39m\u001b[34m(prompts, model_name, max_workers)\u001b[39m\n\u001b[32m     27\u001b[39m latencies = []\n\u001b[32m     28\u001b[39m latencies_lock = threading.Lock()\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture_to_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProcessing with \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdefault\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_to_prompt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/ys-dev/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/ys-dev/lib/python3.11/concurrent/futures/_base.py:243\u001b[39m, in \u001b[36mas_completed\u001b[39m\u001b[34m(fs, timeout)\u001b[39m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[32m    240\u001b[39m                 \u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m) futures unfinished\u001b[39m\u001b[33m'\u001b[39m % (\n\u001b[32m    241\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m waiter.lock:\n\u001b[32m    246\u001b[39m     finished = waiter.finished_futures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/ys-dev/lib/python3.11/threading.py:622\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    620\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/ys-dev/lib/python3.11/threading.py:320\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run the classifier for before and after\n",
    "\n",
    "before = classify_with_model_parallel(prompts, \"gemini-1.5-flash-8b\")                  # None means default, current is gpt-4o-mini\n",
    "after = classify_with_model_parallel(prompts, \"gemini-2.0-flash-001\") \n",
    "after1 = classify_with_model_parallel(prompts, \"Meta-Llama-3.3-70B-Instruct\")  # sambanova\n",
    "after2 = classify_with_model_parallel(prompts, \"llama-3.3-70b-versatile\")   # groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                 start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text',\n",
       "   ['Coding', 'Mathematics', 'offline'],\n",
       "   ['Shorter', 'More structured', 'More formal']),\n",
       "  ('    ifstream file(fileName, ios::binary);\\n    if (!file) {\\n        cout << \"Failed to open file.\\\\n\";\\n        return;\\n    }\\n\\n    vector<string> chunks;\\n    char buffer[CHUNK_SIZE];\\n    int chunkID = 0;\\n\\n    while (file.read(buffer, CHUNK_SIZE) || file.gcount() > 0) {\\n        string chunk(buffer, file.gcount());\\n        string chunkName = fileName + \"_chunk\" + to_string(chunkID++);\\n        chunks.push_back(chunkName);\\n\\n        auto availableNodes = server.getAvailableNodes(world_size);\\n        if (availableNodes.size() < 3) {\\n            cout << \"Not enough nodes available for replication.\\\\n\";\\n            return;\\n        }\\n\\n        vector<int> selectedNodes(availableNodes.begin(), availableNodes.begin() + 3);\\n        server.chunkToNodes[chunkName] = selectedNodes;\\n\\n        for (int node : selectedNodes) {\\n            server.assignTask(node, \"UPLOAD\", chunkName);  // Assign upload task\\n        }\\n    }\\n\\nexplain the code ignore the metadataserver parts, I only want the file reading parts',\n",
       "   ['Coding', 'offline'],\n",
       "   ['Shorter', 'More formal']),\n",
       "  (' hows it going tell me a joke',\n",
       "   ['Small Talk', 'Entertainment', 'offline'],\n",
       "   ['More casual', 'Shorter']),\n",
       "  (' https://www.youtube.com/watch?v=ojULkWEUsPs&pp=ygUUd2hvIGxldCB0aGUgZG9ncyBvdXQ%3D\\nwhat is happening here.',\n",
       "   ['Summarization', 'Analysis', 'online', 'youtube-transcript-yapp'],\n",
       "   ['Shorter', 'More structured', 'More formal', 'Summary'])],\n",
       " [('                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                 start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text',\n",
       "   ['Coding', 'offline'],\n",
       "   ['Shorter', 'More structured', 'More formal', 'More casual', 'Summary']),\n",
       "  ('    ifstream file(fileName, ios::binary);\\n    if (!file) {\\n        cout << \"Failed to open file.\\\\n\";\\n        return;\\n    }\\n\\n    vector<string> chunks;\\n    char buffer[CHUNK_SIZE];\\n    int chunkID = 0;\\n\\n    while (file.read(buffer, CHUNK_SIZE) || file.gcount() > 0) {\\n        string chunk(buffer, file.gcount());\\n        string chunkName = fileName + \"_chunk\" + to_string(chunkID++);\\n        chunks.push_back(chunkName);\\n\\n        auto availableNodes = server.getAvailableNodes(world_size);\\n        if (availableNodes.size() < 3) {\\n            cout << \"Not enough nodes available for replication.\\\\n\";\\n            return;\\n        }\\n\\n        vector<int> selectedNodes(availableNodes.begin(), availableNodes.begin() + 3);\\n        server.chunkToNodes[chunkName] = selectedNodes;\\n\\n        for (int node : selectedNodes) {\\n            server.assignTask(node, \"UPLOAD\", chunkName);  // Assign upload task\\n        }\\n    }\\n\\nexplain the code ignore the metadataserver parts, I only want the file reading parts',\n",
       "   ['Coding', 'offline'],\n",
       "   ['Shorter', 'More structured', 'More formal', 'More casual', 'Summary']),\n",
       "  (' hows it going tell me a joke',\n",
       "   ['Small Talk', 'Entertainment', 'offline'],\n",
       "   ['Shorter', 'More structured', 'More formal']),\n",
       "  (' https://www.youtube.com/watch?v=ojULkWEUsPs&pp=ygUUd2hvIGxldCB0aGUgZG9ncyBvdXQ%3D\\nwhat is happening here.',\n",
       "   ['Summarization', 'online'],\n",
       "   ['Shorter', 'More structured', 'More formal', 'More casual', 'Summary'])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before[:4], after[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category comparison counts:\n",
      "more_before: 425 (20.2%)\n",
      "same: 451 (21.5%)\n",
      "others: 815 (38.8%)\n",
      "more_after: 409 (19.5%)\n",
      "\n",
      "Modifier comparison counts:\n",
      "more_after: 1576 (75.0%)\n",
      "others: 114 (5.4%)\n",
      "same: 315 (15.0%)\n",
      "more_before: 95 (4.5%)\n",
      "\n",
      "Category comparison examples:\n",
      "\n",
      "SAME (451/2100, 21.5%):\n",
      "Prompt:     ifstream file(fileName, ios::binary);\n",
      "    if (!file) {\n",
      "        cout << \"Failed to open file.\\n\";\n",
      "        return;\n",
      "    }\n",
      "\n",
      "    vector<string> chunks;\n",
      "    char buffer[CHUNK_SIZE];\n",
      "    int chunkID = 0;...\n",
      "Before: ['Coding', 'offline']\n",
      "After: ['Coding', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt:  hows it going tell me a joke...\n",
      "Before: ['Small Talk', 'Entertainment', 'offline']\n",
      "After: ['Small Talk', 'Entertainment', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt: 1 + 1 ?...\n",
      "Before: ['Mathematics', 'offline']\n",
      "After: ['Mathematics', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt: 171 * 4 - 1 * 3...\n",
      "Before: ['Mathematics', 'offline']\n",
      "After: ['Mathematics', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt: 2 words from each pdf...\n",
      "Before: ['Summarization', 'offline']\n",
      "After: ['Summarization', 'offline']\n",
      "--------------------------------------------------\n",
      "\n",
      "MORE_BEFORE (425/2100, 20.2%):\n",
      "Prompt:                 start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\n",
      "                #MM:SS - text , example-> 2:00 - text    ...\n",
      "Before: ['Coding', '<Mathematics>', 'offline']\n",
      "After: ['Coding', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt:  https://www.youtube.com/watch?v=ojULkWEUsPs&pp=ygUUd2hvIGxldCB0aGUgZG9ncyBvdXQ%3D\n",
      "what is happening here....\n",
      "Before: ['Summarization', '<Analysis>', 'online', '<youtube-transcript-yapp>']\n",
      "After: ['Summarization', 'online']\n",
      "--------------------------------------------------\n",
      "Prompt: A test is a procedure designed to evaluate knowledge, skills, or the functioning of something.  It can take various forms, including a set of questions, a series of actions, or an experiment under spe...\n",
      "Before: ['Factual', 'Summarization', 'offline', '<wikipedia-yapp>']\n",
      "After: ['Factual', 'Summarization', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt: Are there any other dyes that share similar properties to indigo for dyeing denim?...\n",
      "Before: ['Factual', 'offline', '<wikipedia-yapp>']\n",
      "After: ['Factual', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt: Are there any potential texture issues with using avocado, and how can they be avoided?...\n",
      "Before: ['Advice', 'Factual', 'offline', '<wikipedia-yapp>']\n",
      "After: ['Advice', 'Factual', 'offline']\n",
      "--------------------------------------------------\n",
      "\n",
      "MORE_AFTER (409/2100, 19.5%):\n",
      "Prompt: 1+1 in step by step...\n",
      "Before: ['Mathematics', 'offline']\n",
      "After: ['Mathematics', '<Reasoning>', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt: 150 hourly rate to salary...\n",
      "Before: ['Mathematics', 'offline']\n",
      "After: ['Mathematics', '<Factual>', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt: 300 hourly rate to salary at 40 hours per week...\n",
      "Before: ['Mathematics', 'offline']\n",
      "After: ['Mathematics', '<Factual>', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt: As of my last update, Red Rock Coffee is a popular coffee shop located in Mountain View, California, right in the heart of Silicon Valley. It's known for its community-oriented atmosphere, offering no...\n",
      "Before: ['Factual', 'offline']\n",
      "After: ['Factual', '<Summarization>', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt: Best travel hack. One line answer...\n",
      "Before: ['Advice', 'offline']\n",
      "After: ['Advice', '<Small Talk>', 'offline']\n",
      "--------------------------------------------------\n",
      "\n",
      "OTHERS (815/2100, 38.8%):\n",
      "Prompt:  tell me about your story...\n",
      "Before: ['<Small Talk>', 'offline']\n",
      "After: ['<Creative Writing>', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt: \"Materials.\n",
      "\n",
      "Chemicals were purchased from Sigma/Aldrich/Fluka (Zwijndrecht, The Netherlands) and Acros (Landsmeer, The Netherlands). MMA was distilled at atmospheric pressure and stored at 20 1C. The...\n",
      "Before: ['<Factual>', 'Science', '<Analysis>', 'offline']\n",
      "After: ['Science', '<Advice>', 'offline']\n",
      "--------------------------------------------------\n",
      "Prompt: 1 word from each pdf...\n",
      "Before: ['Summarization', '<offline>']\n",
      "After: ['Summarization', '<online>']\n",
      "--------------------------------------------------\n",
      "Prompt: 24000 + 4.9 interest rate in 36 months what would the monthly payments be...\n",
      "Before: ['Mathematics', '<online>']\n",
      "After: ['Mathematics', '<offline>']\n",
      "--------------------------------------------------\n",
      "Prompt: ANSWER NOW I SAY...\n",
      "Before: ['<Small Talk>', 'Gibberish', '<offline>']\n",
      "After: ['Gibberish', '<online>']\n",
      "--------------------------------------------------\n",
      "\n",
      "Modifier comparison examples:\n",
      "\n",
      "SAME (315/2100, 15.0%):\n",
      "Prompt: \"Materials.\n",
      "\n",
      "Chemicals were purchased from Sigma/Aldrich/Fluka (Zwijndrecht, The Netherlands) and Acros (Landsmeer, The Netherlands). MMA was distilled at atmospheric pressure and stored at 20 1C. The...\n",
      "Before: ['More structured', 'More formal', 'Shorter', 'Summary']\n",
      "After: ['Shorter', 'More structured', 'More formal', 'Summary']\n",
      "--------------------------------------------------\n",
      "Prompt: 2 words from each pdf...\n",
      "Before: ['Shorter', 'More structured', 'Summary']\n",
      "After: ['Shorter', 'More structured', 'Summary']\n",
      "--------------------------------------------------\n",
      "Prompt: Are there any emerging technologies or alternative production methods for food-grade CO2 with reduced environmental impact?...\n",
      "Before: ['Shorter', 'More structured', 'More formal', 'Summary']\n",
      "After: ['Shorter', 'More structured', 'More formal', 'Summary']\n",
      "--------------------------------------------------\n",
      "Prompt: As of my last update, Red Rock Coffee is a popular coffee shop located in Mountain View, California, right in the heart of Silicon Valley. It's known for its community-oriented atmosphere, offering no...\n",
      "Before: ['Shorter', 'More structured', 'More formal', 'More casual', 'Summary']\n",
      "After: ['Shorter', 'More structured', 'More formal', 'More casual', 'Summary']\n",
      "--------------------------------------------------\n",
      "Prompt: Beyond the FGF5 gene, are there other genes or environmental factors that can influence coat length variation in Akitas?...\n",
      "Before: ['Shorter', 'More formal', 'More structured']\n",
      "After: ['Shorter', 'More structured', 'More formal']\n",
      "--------------------------------------------------\n",
      "\n",
      "MORE_BEFORE (95/2100, 4.5%):\n",
      "Prompt: 1+1 in step by step...\n",
      "Before: ['Shorter', 'More structured', '<More formal>']\n",
      "After: ['More structured', 'Shorter']\n",
      "--------------------------------------------------\n",
      "Prompt: 150 hourly rate to salary...\n",
      "Before: ['Shorter', 'More structured', '<More formal>']\n",
      "After: ['Shorter', 'More structured']\n",
      "--------------------------------------------------\n",
      "Prompt: 300 hourly rate to salary at 40 hours per week...\n",
      "Before: ['Shorter', 'More structured', '<More formal>', '<Summary>']\n",
      "After: ['Shorter', 'More structured']\n",
      "--------------------------------------------------\n",
      "Prompt: An image visualizing Pink Floyd's \"Echoes\" could depict several aspects of the song:\n",
      "\n",
      "* The Soundscape: The song's sonic journey could be represented by a blend of vibrant, swirling colors and texture...\n",
      "Before: ['Photorealistic', 'Cartoon', 'Monochromatic', '<More structured>']\n",
      "After: ['Photorealistic', 'Cartoon', 'Monochromatic']\n",
      "--------------------------------------------------\n",
      "Prompt: Apples or bananas. \n",
      "one word answer only....\n",
      "Before: ['Shorter', '<More casual>']\n",
      "After: ['Shorter']\n",
      "--------------------------------------------------\n",
      "\n",
      "MORE_AFTER (1576/2100, 75.0%):\n",
      "Prompt:                 start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\n",
      "                #MM:SS - text , example-> 2:00 - text    ...\n",
      "Before: ['Shorter', 'More structured', 'More formal']\n",
      "After: ['Shorter', 'More structured', 'More formal', '<More casual>', '<Summary>']\n",
      "--------------------------------------------------\n",
      "Prompt:     ifstream file(fileName, ios::binary);\n",
      "    if (!file) {\n",
      "        cout << \"Failed to open file.\\n\";\n",
      "        return;\n",
      "    }\n",
      "\n",
      "    vector<string> chunks;\n",
      "    char buffer[CHUNK_SIZE];\n",
      "    int chunkID = 0;...\n",
      "Before: ['Shorter', 'More formal']\n",
      "After: ['Shorter', '<More structured>', 'More formal', '<More casual>', '<Summary>']\n",
      "--------------------------------------------------\n",
      "Prompt:  https://www.youtube.com/watch?v=ojULkWEUsPs&pp=ygUUd2hvIGxldCB0aGUgZG9ncyBvdXQ%3D\n",
      "what is happening here....\n",
      "Before: ['Shorter', 'More structured', 'More formal', 'Summary']\n",
      "After: ['Shorter', 'More structured', 'More formal', '<More casual>', 'Summary']\n",
      "--------------------------------------------------\n",
      "Prompt:  tell me about your story...\n",
      "Before: ['Shorter', 'More casual', 'More formal', 'Summary']\n",
      "After: ['Shorter', '<More structured>', 'More formal', 'More casual', 'Summary']\n",
      "--------------------------------------------------\n",
      "Prompt: 1 + 1 ?...\n",
      "Before: ['Shorter', 'More formal']\n",
      "After: ['Shorter', '<More structured>', 'More formal', '<More casual>', '<Summary>']\n",
      "--------------------------------------------------\n",
      "\n",
      "OTHERS (114/2100, 5.4%):\n",
      "Prompt:  hows it going tell me a joke...\n",
      "Before: ['<More casual>', 'Shorter']\n",
      "After: ['Shorter', '<More structured>', '<More formal>']\n",
      "--------------------------------------------------\n",
      "Prompt: A highly detailed, photorealistic, 4K resolution, monochrome photograph of a sleek robotic arm. The arm displays intricate mechanical joints, precise metal surfaces with subtle reflections, meticulous...\n",
      "Before: ['<Photorealistic>', '<Monochromatic>', 'More structured']\n",
      "After: ['<Shorter>', 'More structured', '<More formal>', '<More casual>', '<Summary>']\n",
      "--------------------------------------------------\n",
      "Prompt: At what point in the video does he talk about Munich 1938?...\n",
      "Before: ['Shorter', '<More formal>']\n",
      "After: ['Shorter', '<More structured>']\n",
      "--------------------------------------------------\n",
      "Prompt: Batman close-up portrait, muscular armored suit with detailed textures and panels, dramatic side lighting, cyberpunk city backdrop with blue and orange gradient sky. Strong silhouette, menacing pose, ...\n",
      "Before: ['Photorealistic', '<More formal>']\n",
      "After: ['Photorealistic', '<Cartoon>', '<Monochromatic>']\n",
      "--------------------------------------------------\n",
      "Prompt: Best travel hack. One line answer...\n",
      "Before: ['Shorter', '<More formal>']\n",
      "After: ['Shorter', '<Summary>']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from typing import Literal, TypeAlias\n",
    "\n",
    "ComparisonResult: TypeAlias = Literal[\"same\", \"more_before\", \"more_after\", \"others\"]\n",
    "\n",
    "def compare_lists(before: list[str], after: list[str]) -> ComparisonResult:\n",
    "    before_set = set(before)\n",
    "    after_set = set(after)\n",
    "    \n",
    "    if before_set == after_set:\n",
    "        return \"same\"\n",
    "    elif before_set.issubset(after_set):  # before is all in after\n",
    "        return \"more_after\"\n",
    "    elif after_set.issubset(before_set):  # after is all in before\n",
    "        return \"more_before\"\n",
    "    else:\n",
    "        return \"others\"\n",
    "\n",
    "\n",
    "before_results = before\n",
    "after_results = after\n",
    "    \n",
    "category_comparisons: list[tuple[str, ComparisonResult, list[str], list[str]]] = []\n",
    "modifier_comparisons: list[tuple[str, ComparisonResult, list[str], list[str]]] = []\n",
    "\n",
    "for (prompt1, cats1, mods1), (prompt2, cats2, mods2) in zip(before_results, after_results):\n",
    "    assert prompt1 == prompt2, f\"Prompts don't match: {prompt1} vs {prompt2}\"\n",
    "    \n",
    "    cat_result = compare_lists(cats1, cats2)\n",
    "    mod_result = compare_lists(mods1, mods2)\n",
    "    \n",
    "    category_comparisons.append((prompt1, cat_result, cats1, cats2))\n",
    "    modifier_comparisons.append((prompt1, mod_result, mods1, mods2))\n",
    "\n",
    "# Count results\n",
    "cat_counts = Counter(comp[1] for comp in category_comparisons)\n",
    "mod_counts = Counter(comp[1] for comp in modifier_comparisons)\n",
    "\n",
    "# Store results in separate lists for categories and modifiers\n",
    "cat_results = []\n",
    "mod_results = []\n",
    "for (prompt, cat_diff, cats_before, cats_after), (_, mod_diff, mods_before, mods_after) in zip(category_comparisons, modifier_comparisons):\n",
    "    cat_results.append((\n",
    "        prompt,\n",
    "        cat_diff,\n",
    "        cats_before,\n",
    "        cats_after\n",
    "    ))\n",
    "    mod_results.append((\n",
    "        prompt, \n",
    "        mod_diff,\n",
    "        mods_before,\n",
    "        mods_after\n",
    "    ))\n",
    "\n",
    "# Print category comparison counts\n",
    "print(\"Category comparison counts:\")\n",
    "for result, count in cat_counts.items():\n",
    "    print(f\"{result}: {count} ({count/sum(cat_counts.values())*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nModifier comparison counts:\")\n",
    "for result, count in mod_counts.items():\n",
    "    print(f\"{result}: {count} ({count/sum(mod_counts.values())*100:.1f}%)\")\n",
    "\n",
    "# Show examples\n",
    "cat_marked_results = []\n",
    "mod_marked_results = []\n",
    "\n",
    "print(\"\\nCategory comparison examples:\")\n",
    "for result in [\"same\",\"more_before\", \"more_after\", \"others\"]:\n",
    "    examples = [r for r in cat_results if r[1] == result][:5]\n",
    "    if examples:\n",
    "        total = len(cat_results)\n",
    "        count = len([r for r in cat_results if r[1] == result])\n",
    "        pct = count / total * 100\n",
    "        print(f\"\\n{result.upper()} ({count}/{total}, {pct:.1f}%):\")\n",
    "        for prompt, diff_type, before_cats, after_cats in examples:\n",
    "            print(f\"Prompt: {prompt[:200]}...\")\n",
    "            # Mark differences between before and after\n",
    "            before_marked = [cat if cat in after_cats else f\"<{cat}>\" for cat in before_cats]\n",
    "            after_marked = [cat if cat in before_cats else f\"<{cat}>\" for cat in after_cats]\n",
    "            cat_marked_results.append((prompt, diff_type, before_marked, after_marked))\n",
    "            print(f\"Before: {before_marked}\")\n",
    "            print(f\"After: {after_marked}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nModifier comparison examples:\")\n",
    "for result in [\"same\", \"more_before\", \"more_after\", \"others\"]:\n",
    "    examples = [r for r in mod_results if r[1] == result][:5]\n",
    "    if examples:\n",
    "        total = len(mod_results)\n",
    "        count = len([r for r in mod_results if r[1] == result])\n",
    "        pct = count / total * 100\n",
    "        print(f\"\\n{result.upper()} ({count}/{total}, {pct:.1f}%):\")\n",
    "        for prompt, diff_type, before_mods, after_mods in examples:\n",
    "            print(f\"Prompt: {prompt[:200]}...\")\n",
    "            # Mark differences between before and after\n",
    "            before_marked = [mod if mod in after_mods else f\"<{mod}>\" for mod in before_mods]\n",
    "            after_marked = [mod if mod in before_mods else f\"<{mod}>\" for mod in after_mods]\n",
    "            mod_marked_results.append((prompt, diff_type, before_marked, after_marked))\n",
    "            print(f\"Before: {before_marked}\")\n",
    "            print(f\"After: {after_marked}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('    ifstream file(fileName, ios::binary);\\n    if (!file) {\\n        cout << \"Failed to open file.\\\\n\";\\n        return;\\n    }\\n\\n    vector<string> chunks;\\n    char buffer[CHUNK_SIZE];\\n    int chunkID = 0;\\n\\n    while (file.read(buffer, CHUNK_SIZE) || file.gcount() > 0) {\\n        string chunk(buffer, file.gcount());\\n        string chunkName = fileName + \"_chunk\" + to_string(chunkID++);\\n        chunks.push_back(chunkName);\\n\\n        auto availableNodes = server.getAvailableNodes(world_size);\\n        if (availableNodes.size() < 3) {\\n            cout << \"Not enough nodes available for replication.\\\\n\";\\n            return;\\n        }\\n\\n        vector<int> selectedNodes(availableNodes.begin(), availableNodes.begin() + 3);\\n        server.chunkToNodes[chunkName] = selectedNodes;\\n\\n        for (int node : selectedNodes) {\\n            server.assignTask(node, \"UPLOAD\", chunkName);  // Assign upload task\\n        }\\n    }\\n\\nexplain the code ignore the metadataserver parts, I only want the file reading parts',\n",
       "  'same',\n",
       "  ['Coding', 'offline'],\n",
       "  ['Coding', 'offline']),\n",
       " (' hows it going tell me a joke',\n",
       "  'same',\n",
       "  ['Small Talk', 'Entertainment', 'offline'],\n",
       "  ['Small Talk', 'Entertainment', 'offline']),\n",
       " ('1 + 1 ?', 'same', ['Mathematics', 'offline'], ['Mathematics', 'offline']),\n",
       " ('171 * 4 - 1 * 3',\n",
       "  'same',\n",
       "  ['Mathematics', 'offline'],\n",
       "  ['Mathematics', 'offline']),\n",
       " ('2 words from each pdf',\n",
       "  'same',\n",
       "  ['Summarization', 'offline'],\n",
       "  ['Summarization', 'offline']),\n",
       " ('                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                 start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text                start_time_well_formatted_and_text = [f\"{int(s[0]//60):02d}:{int(s[0]%60):02d} - {s[1]}\" for s in start_time_seconds_and_text]\\n                #MM:SS - text , example-> 2:00 - text',\n",
       "  'more_before',\n",
       "  ['Coding', '<Mathematics>', 'offline'],\n",
       "  ['Coding', 'offline']),\n",
       " (' https://www.youtube.com/watch?v=ojULkWEUsPs&pp=ygUUd2hvIGxldCB0aGUgZG9ncyBvdXQ%3D\\nwhat is happening here.',\n",
       "  'more_before',\n",
       "  ['Summarization', '<Analysis>', 'online', '<youtube-transcript-yapp>'],\n",
       "  ['Summarization', 'online']),\n",
       " (\"A test is a procedure designed to evaluate knowledge, skills, or the functioning of something.  It can take various forms, including a set of questions, a series of actions, or an experiment under specific conditions. Tests are used in many contexts, from education and hiring to scientific research and product development.  There are several types of tests, such as aptitude tests that measure potential, achievement tests that gauge learning, and diagnostic tests used to identify issues or substances.  Tests can also refer to trials meant to determine the quality, effectiveness, or reliability of something.  Additionally, in some contexts, a test can be a challenging situation that reveals one's character or capabilities.\",\n",
       "  'more_before',\n",
       "  ['Factual', 'Summarization', 'offline', '<wikipedia-yapp>'],\n",
       "  ['Factual', 'Summarization', 'offline']),\n",
       " ('Are there any other dyes that share similar properties to indigo for dyeing denim?',\n",
       "  'more_before',\n",
       "  ['Factual', 'offline', '<wikipedia-yapp>'],\n",
       "  ['Factual', 'offline']),\n",
       " ('Are there any potential texture issues with using avocado, and how can they be avoided?',\n",
       "  'more_before',\n",
       "  ['Advice', 'Factual', 'offline', '<wikipedia-yapp>'],\n",
       "  ['Advice', 'Factual', 'offline'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_marked_results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV files\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataFrames\n",
    "cat_df = pd.DataFrame(cat_marked_results, columns=['Prompt', 'Diff_Type', 'Before_Categories', 'After_Categories'])\n",
    "mod_df = pd.DataFrame(mod_marked_results, columns=['Prompt', 'Diff_Type', 'Before_Modifiers', 'After_Modifiers'])\n",
    "\n",
    "CSV_CAT = \"/Users/wangtian/tmp/diff-gemini15-20-category.csv\"\n",
    "CSV_MOD = \"/Users/wangtian/tmp/diff-gemini15-20-modifier.csv\"\n",
    "\n",
    "# Save to CSV files\n",
    "cat_df.to_csv(CSV_CAT, index=False)\n",
    "mod_df.to_csv(CSV_MOD, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ys-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
